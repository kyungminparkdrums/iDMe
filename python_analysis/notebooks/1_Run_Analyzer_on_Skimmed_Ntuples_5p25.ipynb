{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ee842b-e6f4-4bcd-8f52-957ba88275b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import awkward as ak\n",
    "import importlib\n",
    "import coffea.util as util\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/uscms/home/kyungmip/nobackup/CMSSW_10_6_26/src/iDMe/python_analysis/analysisTools/\")\n",
    "from analysisTools import Analyzer\n",
    "from analysisTools import loadSchema\n",
    "import analysisTools as tools\n",
    "import analysisSubroutines as routines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ab31af-f2b2-441d-895b-cd38385311b0",
   "metadata": {},
   "source": [
    "### Input files to be analyzed\n",
    "Coffea analyzer will analyze the ntuples that skimmed AOD. The skimmed ntuples information (file location, xsec, lumi, weight, etc) is available as sample config json files and the json files are given as input to the analyzer. \n",
    "\n",
    "The workflow is as follows:\n",
    "1) `EDAnalyzer` format ntuplizer is run on AOD, saving useful branches: `/AODSkimmer/`\n",
    "2) `rdataframe` format skimmer is run on the ntuples, applying basic cuts (MET filter, trigger, MET cut etc): `/python_analysis/condor/condor_skim_rdf.py`\n",
    "3) `coffea` format analyzer is run on the skimmed files, applying the rest of the cuts. This step is done in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d67d303-bf5f-4a01-9ad8-9b11bd558c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bkg_2018_Diboson.json, can't find original file\n",
      "Skipping bkg_2018_DY.json, can't find original file\n",
      "Skipping bkg_2018_QCD_TuneCP5_PSWeights.json, can't find original file\n",
      "Skipping bkg_2018_Top.json, can't find original file\n",
      "Skipping bkg_2018_Triboson.json, can't find original file\n",
      "Skipping bkg_2018_TTJetsDiLept.json, can't find original file\n",
      "Skipping bkg_2018_WJets.json, can't find original file\n",
      "Skipping bkg_2018_ZJets.json, can't find original file\n",
      "Skipping signal_v2_2018_aEM.json, can't find original file\n",
      "Skipping signal_2018_aEM_5p25.json, can't find original file\n",
      "Skipping signal_2018_aEM_5p25_ct_1.json, can't find original file\n"
     ]
    }
   ],
   "source": [
    "# update jsons from original ones in case cross section, number of files, etc has updated\n",
    "sample_json_dir = './'\n",
    "\n",
    "src = \"/uscms/home/kyungmip/nobackup/CMSSW_10_6_26/src/iDMe/python_analysis/analysisTools/configs/sample_configs/\"\n",
    "jsons = [f for f in os.listdir(sample_json_dir) if \".json\" in f]\n",
    "for jf in jsons:\n",
    "    if not os.path.exists(src+jf):\n",
    "        print(f\"Skipping {jf}, can't find original file\")\n",
    "        continue\n",
    "    with open(src+jf,\"r\") as sf:\n",
    "        source = json.load(sf)\n",
    "    with open(jf,\"r\") as tf:\n",
    "        targ = json.load(tf)\n",
    "    for i,entry in enumerate(targ):\n",
    "        src_entry = [k for k in source if k['name']==entry['name']][0]\n",
    "        entry['xsec'] = src_entry['xsec']\n",
    "        entry['sum_wgt'] = src_entry['sum_wgt']\n",
    "        entry['nFiles'] = src_entry['nFiles']\n",
    "        if 'num_events' in src_entry.keys():\n",
    "            entry['num_events'] = src_entry['num_events']\n",
    "    with open(jf,\"w\") as of:\n",
    "        json.dump(targ,of,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b6fd4fb-4097-4a15-8f3b-132bad756c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_file = \"./configs/cut_configs/SR_fromSkimmed_v1.py\"\n",
    "hist_file = \"./configs/histo_configs/SR_studies.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adbf76c6-5416-4e6c-997f-4b8898298ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdir = \"./coffea/\"\n",
    "os.system(f\"mkdir -p {outdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46bcef59-54c2-47d9-b622-26ff458807f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coffea output file name suffix\n",
    "\n",
    "#suffix = \"_ejdR_rejection_IDcut\"\n",
    "suffix = \"_deltaR_nGoodVtx_finer_dR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4cd5e9-958f-44ff-bd6f-cc03b7dd54e1",
   "metadata": {},
   "source": [
    "### Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3204c9d7-7bc8-40c1-89e2-264c9abd129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['signal_2018_aEM_5p25_ct_1']\n"
     ]
    }
   ],
   "source": [
    "signal_list = [ samp.split('.')[0] for samp in jsons if \"signal_2018_aEM_5p25_ct_1\" in samp ]\n",
    "print(signal_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60416c18-500c-4270-8aea-1139fdec5aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start analyzing: signal_2018_aEM_5p25_ct_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6775793c29124b739792e2a536080002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb56befd9f94e90b701423e8a31686d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "concurrent.futures.process._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py\", line 1654, in _work_function\n",
      "    out = processor_instance.process(events)\n",
      "  File \"/uscms/home/kyungmip/nobackup/CMSSW_10_6_26/src/iDMe/python_analysis/analysisTools/analysisTools.py\", line 240, in process\n",
      "    routines.selectExistingGoodVtx(events)\n",
      "  File \"/uscms/home/kyungmip/nobackup/CMSSW_10_6_26/src/iDMe/python_analysis/analysisTools/analysisSubroutines.py\", line 80, in selectExistingGoodVtx\n",
      "    events[\"LptElectron\",\"dPhij1\"] = ak.where(j1_phi != -999,np.abs(deltaPhi(events.LptElectron.phi,j1_phi)),999)\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/awkward/highlevel.py\", line 1062, in __setitem__\n",
      "    array = ak.operations.structure.with_field(self.layout, what, where)\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/awkward/operations/structure.py\", line 971, in with_field\n",
      "    with_field(\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/awkward/operations/structure.py\", line 1038, in with_field\n",
      "    out = ak._util.broadcast_and_apply(\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/awkward/_util.py\", line 1172, in broadcast_and_apply\n",
      "    out = apply(broadcast_pack(inputs, isscalar), 0, user)\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/awkward/_util.py\", line 925, in apply\n",
      "    outcontent = apply(nextinputs, depth + 1, user)\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/awkward/_util.py\", line 842, in apply\n",
      "    return tuple(\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/awkward/_util.py\", line 843, in <genexpr>\n",
      "    ak.layout.UnionArray8_64(\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/awkward/operations/convert.py\", line 4759, in _form_to_layout\n",
      "    raise ValueError(\n",
      "ValueError: buffer is too short for NumpyArray: expected 839, buffer has 0 items (0 bytes)\n",
      "\n",
      "(https://github.com/scikit-hep/awkward-1.0/blob/1.10.3/src/awkward/operations/convert.py#L4762)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/concurrent/futures/process.py\", line 239, in _process_worker\n",
      "    r = call_item.fn(*call_item.args, **call_item.kwargs)\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py\", line 221, in __call__\n",
      "    out = self.function(*args, **kwargs)\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py\", line 1367, in automatic_retries\n",
      "    raise e\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py\", line 1336, in automatic_retries\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py\", line 1656, in _work_function\n",
      "    raise Exception(f\"Failed processing file: {item!r}\") from e\n",
      "Exception: Failed processing file: WorkItem(dataset='sig_2018_Mchi-5p25_dMchi-0p5_ctau-1', filename='root://cmsxrootd.fnal.gov//store/group/lpcmetx/iDMe/skimmed_ntuples/signal/signal_v2_2018_5p25_aEM_rdfSkim/output_sig_Mchi-5p25_dMchi-0p5_ct-1//ntuples_sig_Mchi-5.25_dMchi-0.5_ct-1_3.root', treename='ntuples/outT', entrystart=0, entrystop=709, fileuuid=b'\\xfe\\xaa\\xa1\\x8c_\\xc9\\x11\\xee\\xadu\\x9d\\xbc\\xe1\\x83\\xbe\\xef', usermeta={})\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py\", line 786, in _processwith\n",
      "    merged = _watcher(FH, self, reducer, pool)\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py\", line 402, in _watcher\n",
      "    batch = FH.fetch(len(FH.completed))\n",
      "  File \"/uscms/home/kyungmip/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py\", line 286, in fetch\n",
      "    raise bad_futures[0].exception()\n",
      "Exception: Failed processing file: WorkItem(dataset='sig_2018_Mchi-5p25_dMchi-0p5_ctau-1', filename='root://cmsxrootd.fnal.gov//store/group/lpcmetx/iDMe/skimmed_ntuples/signal/signal_v2_2018_5p25_aEM_rdfSkim/output_sig_Mchi-5p25_dMchi-0p5_ct-1//ntuples_sig_Mchi-5.25_dMchi-0.5_ct-1_3.root', treename='ntuples/outT', entrystart=0, entrystop=709, fileuuid=b'\\xfe\\xaa\\xa1\\x8c_\\xc9\\x11\\xee\\xadu\\x9d\\xbc\\xe1\\x83\\xbe\\xef', usermeta={})\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed processing file: WorkItem(dataset='sig_2018_Mchi-5p25_dMchi-0p5_ctau-1', filename='root://cmsxrootd.fnal.gov//store/group/lpcmetx/iDMe/skimmed_ntuples/signal/signal_v2_2018_5p25_aEM_rdfSkim/output_sig_Mchi-5p25_dMchi-0p5_ct-1//ntuples_sig_Mchi-5.25_dMchi-0.5_ct-1_3.root', treename='ntuples/outT', entrystart=0, entrystop=709, fileuuid=b'\\xfe\\xaa\\xa1\\x8c_\\xc9\\x11\\xee\\xadu\\x9d\\xbc\\xe1\\x83\\xbe\\xef', usermeta={})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m test \u001b[38;5;241m=\u001b[39m Analyzer(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,hist_file,cut_file)\n\u001b[1;32m      6\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 7\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfutures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     10\u001b[0m util\u001b[38;5;241m.\u001b[39msave(out, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.coffea\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/nobackup/CMSSW_10_6_26/src/iDMe/python_analysis/analysisTools/analysisTools.py:119\u001b[0m, in \u001b[0;36mAnalyzer.process\u001b[0;34m(self, treename, execr, workers, lite)\u001b[0m\n\u001b[1;32m    117\u001b[0m     exit\n\u001b[1;32m    118\u001b[0m runner \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mRunner(executor\u001b[38;5;241m=\u001b[39mexecutor,schema\u001b[38;5;241m=\u001b[39mMySchema,savemetrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 119\u001b[0m accumulator \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtreename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtreename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mprocessor_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py:1700\u001b[0m, in \u001b[0;36mRunner.__call__\u001b[0;34m(self, fileset, treename, processor_instance)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1680\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1681\u001b[0m     fileset: Dict,\n\u001b[1;32m   1682\u001b[0m     treename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   1683\u001b[0m     processor_instance: ProcessorABC,\n\u001b[1;32m   1684\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Accumulatable:\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the processor_instance on a given fileset\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \n\u001b[1;32m   1687\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m \u001b[38;5;124;03m            An instance of a class deriving from ProcessorABC\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1700\u001b[0m     wrapped_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1701\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dataframes:\n\u001b[1;32m   1702\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_out  \u001b[38;5;66;03m# not wrapped anymore\u001b[39;00m\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py:1848\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, fileset, processor_instance, treename)\u001b[0m\n\u001b[1;32m   1843\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautomatic_retries, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipbadfiles, closure\n\u001b[1;32m   1845\u001b[0m )\n\u001b[1;32m   1847\u001b[0m executor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutor\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexe_args)\n\u001b[0;32m-> 1848\u001b[0m wrapped_out, e \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrapped_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1851\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo chunks returned results, verify ``processor`` instance structure.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;124m        if you used skipbadfiles=True, it is possible all your files are bad.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1853\u001b[0m     )\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py:817\u001b[0m, in \u001b[0;36mFuturesExecutor.__call__\u001b[0;34m(self, items, function, accumulator)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    816\u001b[0m     mergepoolinstance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 817\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_processwith\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoolinstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmergepool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmergepoolinstance\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py:801\u001b[0m, in \u001b[0;36mFuturesExecutor.__call__.<locals>._processwith\u001b[0;34m(pool, mergepool)\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accumulate([_decompress(merged), accumulator]), e\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 801\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py:786\u001b[0m, in \u001b[0;36mFuturesExecutor.__call__.<locals>._processwith\u001b[0;34m(pool, mergepool)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mergepool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 786\u001b[0m         merged \u001b[38;5;241m=\u001b[39m \u001b[43m_watcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreducer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    788\u001b[0m         merged \u001b[38;5;241m=\u001b[39m _watcher(FH, \u001b[38;5;28mself\u001b[39m, reducer, mergepool)\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py:402\u001b[0m, in \u001b[0;36m_watcher\u001b[0;34m(FH, executor, merge_fcn, pool)\u001b[0m\n\u001b[1;32m    396\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    397\u001b[0m                 p_idm,\n\u001b[1;32m    398\u001b[0m                 total\u001b[38;5;241m=\u001b[39mprogress\u001b[38;5;241m.\u001b[39m_tasks[p_idm]\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    399\u001b[0m                 refresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m             )\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Merge within process\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[43mFH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompleted\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m         merged \u001b[38;5;241m=\u001b[39m _compress(\n\u001b[1;32m    404\u001b[0m             accumulate(\n\u001b[1;32m    405\u001b[0m                 progress\u001b[38;5;241m.\u001b[39mtrack(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m             executor\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[1;32m    413\u001b[0m         )\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# Add checkpointing\u001b[39;00m\n",
      "File \u001b[0;32m~/nobackup/miniconda3/envs/coffea/lib/python3.8/site-packages/coffea/processor/executor.py:286\u001b[0m, in \u001b[0;36m_FuturesHolder.fetch\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    284\u001b[0m bad_futures \u001b[38;5;241m=\u001b[39m [future \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m _completed \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _good_future(future)]\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompleted\u001b[38;5;241m.\u001b[39mupdate(good_futures)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m bad_futures[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[0;31mException\u001b[0m: Failed processing file: WorkItem(dataset='sig_2018_Mchi-5p25_dMchi-0p5_ctau-1', filename='root://cmsxrootd.fnal.gov//store/group/lpcmetx/iDMe/skimmed_ntuples/signal/signal_v2_2018_5p25_aEM_rdfSkim/output_sig_Mchi-5p25_dMchi-0p5_ct-1//ntuples_sig_Mchi-5.25_dMchi-0.5_ct-1_3.root', treename='ntuples/outT', entrystart=0, entrystop=709, fileuuid=b'\\xfe\\xaa\\xa1\\x8c_\\xc9\\x11\\xee\\xadu\\x9d\\xbc\\xe1\\x83\\xbe\\xef', usermeta={})"
     ]
    }
   ],
   "source": [
    "for samp in signal_list:\n",
    "    print(f'Start analyzing: {samp}')\n",
    "    \n",
    "    test = Analyzer(f\"{samp}.json\",hist_file,cut_file)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    out = test.process(execr='futures',lite=True)\n",
    "    t2 = time.time()\n",
    "    \n",
    "    util.save(out, f\"{outdir}/{samp}{suffix}.coffea\")\n",
    "    \n",
    "    print('Completed in {:.2f} min\\n'.format((t2-t1)/60))\n",
    "    del out, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511619cc-608a-4fb3-8426-39dba14eaeca",
   "metadata": {},
   "source": [
    "### Backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dbde10-4d1f-4c2a-98ab-766aca0e5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_list = [ samp.split('.')[0] for samp in jsons if \"bkg\" in samp ]\n",
    "print(bkg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f72c3-06ca-4e1e-9108-0ae19f25ab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for samp in bkg_list:\n",
    "    print(f'Start analyzing: {samp}')\n",
    "    \n",
    "    test = Analyzer(f\"{samp}.json\",hist_file,cut_file)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    out = test.process(execr='futures',lite=True)\n",
    "    t2 = time.time()\n",
    "    \n",
    "    util.save(out, f\"{outdir}/{samp}{suffix}.coffea\")\n",
    "    \n",
    "    print('Completed in {:.2f} min\\n'.format((t2-t1)/60))\n",
    "    del out, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fe33c9-b83c-4cf1-bb01-69a85782d4de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb620e71-3afc-4bdb-94e1-f5943c0bd1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31273b97-5981-42a1-a8ac-d5dd93d034ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
